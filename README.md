
## Real-Time Spotify Control with Hand Gestures using Raspberry Pi & MediaPipe

### Overview

This project demonstrates a **gesture-controlled media interface** designed to control **Spotify playback** using a USB camera and real-time hand detection. Built on **Raspberry Pi 4** and leveraging **MediaPipe** and **OpenCV**, it allows users to interact through **natural hand gestures** (such as play, pause, next track, and volume control) without touching any device.

The core of the system lies in **computer vision** and **signal processing** principles. While the implementation primarily relies on landmark tracking through MediaPipe, foundational knowledge from **Fast Fourier Transform (FFT)** is applied to understand and support motion analysis in gesture-based input.



## Key Features

### Gesture-Based Playback Control

* Open Palm â†’ Play / Pause
* Fist â†’ Stop
* Pinch Gesture â†’ Volume Control
* 3 Fingers â†’ Previous Track
* 4 Fingers â†’ Next Track

### Real-Time Hand Tracking

* 21 keypoint landmark detection using MediaPipe Hands
* Smooth visualization and robust frame-by-frame gesture updates

### Signal Processing Foundation

* **Fast Fourier Transform (FFT)** supports understanding motion frequency (slow/fast movements)
* Discusses theoretical application of signal analysis in visual inputs

### Simple UI & Feedback

* Terminal logs current gesture detected
* Visual feedback via OpenCV window with bounding/landmark overlays

---

## Technical Specifications

| Category             | Details                                          |
| -------------------- | ------------------------------------------------ |
| Platform             | Raspberry Pi 4 Model B                           |
| Camera Input         | USB Webcam                 |
| Frameworks           | MediaPipe, OpenCV                                |
| Resolution           | 640Ã—480 @ 30 FPS                                 |
| Gesture Recognition  | Static + Dynamic Hand Tracking via Landmarks     |
| Signal Techniques    | FFT (Fast Fourier Transform) for motion insights |
| Accuracy             | 85â€“90% (Static), \~80â€“85% (Dynamic Gestures)     |
| Latency              | \~10â€“15 ms depending on gesture & light          |
| Programming Language | Python 3.8.10 or 3.9                                     |

---

## Requirements

* Python 3.8.10/3.9
* OpenCV
* MediaPipe
* pyautogui
* Raspberry Pi 4
* USB Webcam

```bash
pip install opencv-python mediapipe pyautogui
```

---

## Installation

```bash
git clone https://github.com/sherilynso/spotifygesturecontroller.git
cd gesture-spotify-controller
pip install -r requirements.txt
```

> Make sure your USB webcam is connected and testable with `cv2.VideoCapture(0)`.

---

## ðŸ› Usage

```bash
python3 main.py
```

The system will:

* Launch webcam capture
* Detect hand gestures
* Trigger Spotify media controls (play/pause/next/volume)
* Overlay visual landmark feedback

**To exit:** press `ESC`.

---

## Demo Preview

| Open Palm â€“ Play/Pause   | Volume Pinch Gesture        |
| ------------------------ | --------------------------- |
| ![play](images/palm.png) | ![volume](images/pinch.png) |

> Demo video: [ðŸŽ¬ Click here](media/demo.mp4)




## Signal Processing Insight (FFT)

While the implementation uses computer vision, the **Fast Fourier Transform (FFT)** underpins the theoretical backbone. A gesture (like a swipe) can be analyzed as a **time-varying signal**.

* **FFT** breaks down hand motion into frequency components
* **Low-frequency = slow hand wave**
* **High-frequency = fast gesture**
* Future versions can apply FFT for noise filtering or gesture classification

Although FFT isn't directly coded in this version, understanding it is crucial to improving detection in noisy video input environments.

---

## References

* Wei, J. (n.d.). *Hand Gesture Recognition* \[GitHub Repository]. [https://github.com/weijie7/Hand-Gesture-Recognition](https://github.com/weijie7/Hand-Gesture-Recognition)
* Zaleska, K. (n.d.). *Spotify Gesture Controller* \[GitHub Repository]. [https://github.com/kzaleskaa/spotify-gesture-controller](https://github.com/kzaleskaa/spotify-gesture-controller)
* Zhou, Z., et al. (2020). *Hand Tracking with MediaPipe*. Google AI Blog.
* OpenCV Documentation: [https://docs.opencv.org](https://docs.opencv.org)
* MediaPipe Hands Solution: [https://mediapipe.readthedocs.io/en/latest/solutions/hands.html](https://mediapipe.readthedocs.io/en/latest/solutions/hands.html)
* Gautam, A. (n.d.). *Hand Recognition using OpenCV*. [https://gautamaditee.medium.com/hand-recognition-using-opencv-a7b109941c88](https://gautamaditee.medium.com/hand-recognition-using-opencv-a7b109941c88)
* PyAutoGUI Docs: [https://pyautogui.readthedocs.io](https://pyautogui.readthedocs.io)

---

## License

This project is licensed under the **MIT License**.
Â© 2025 YourName


